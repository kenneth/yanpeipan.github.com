---
layout: post
title: "大规模Web服务开发技术"
description: ""
category: 
tags: []
---
{% include JB/setup %}

---

# 大规模Web服务的开发定位——掌握整体

## 大规模和小规模服务

* Alexa排名
* 服务规模可以大致通过服务器数量来把握， 从这个观点来说， 上百台至几千台左右可以称为大规模。

### 小规模服务和大规模服务的区别

1. 保证可扩展性， 负载均衡的必要性
* 横向扩展（scale out）：通过增加服务器数量来提高系统整体的处理能力并分担负载。
* 纵向扩展（scale up）：通过提高硬件性能来提高处理能力。
2. 保证冗余性
3. 低成本运维的重要性
4. 开发人数和开发方法的变化

## 应对大规模数据量

现代计算机的特点， 就是各层之间的速度差异非常大。即使操作系统和中间件再努力，也是有极限的。数据量增大， 就会经常发生缓存不命中， 结果就要多次访问低速磁盘。进入磁盘I/O（输入输出）等待队列的程序在等待读取完成之时，即使其他资源空闲， 也无法进行下一步处理。这就会导致系统整体的速度下降。

---

# 持续增长的服务和大规模化的障碍

## 系统增长战略——最小化开端， 预见变化的管理和设计

1. 事先考虑到未来系统规模会变大，从而一开始就建立完善的负载均衡系统的话，成本实在是太高了。
2. 不假思索地开始也是欠考虑的。数据规模增大引起的I/O负载上升并不是平滑增加。从缓存不命中开始只需片刻， 问题就会急剧显露出来， 引起人们注意时， 系统速度就已经开始下降了——这种事情是极其常见的。
3. 最小化开端， 在关键的地方为将来的增长做好规划， 又不致花费过多的开销。

---

# 大规模数据处理的难点——内存和磁盘

## 为何处理大规模数据如此困难——因为无法在内存中计算

无法在内存中计算的话， 就必须搜索磁盘上的数据， 但是磁盘十分缓慢， I/O十分耗费时间。

## 内存和磁盘的速度差异——内存要快10^5-10^6倍

内存比磁盘快10w-100w倍。

## 操作系统层的加速处理

操作系统将连续的数据放在同一处， 一次性读取4KB（kilobytes）左右。其结果就是将磁盘旋转次数降到最低。这种处理尽量减少磁盘旋转。尽管如此， 旋转一次也需要花费毫秒级，所以与内存的速度差异还是不可避免的。

## 传输速度和总线的速度差异

内存的搜索速度是磁盘的10^5-10^6倍以上， 不论内存还是磁盘， 都用总线与CPU连接。 这些总线的传输速度也有差异。连接内存和CPU的总线相当快，能达到7.5G/s， 但磁盘只能达到58M/s。SSD（solid State Drive， 固态硬盘）不需要物理旋转即可进行高速搜索， 但由于总线速度的瓶颈以及其他结构的影响， 其速度还是无法与内存相比。

在现代计算机上编写应用程序时， 必须考虑到内存和磁盘的速度差异。这是考虑可扩展性（scalability)时及其主要的一点， 也是非常困难的一点。

## 不要推测， 要测量——将一台服务器的性能发挥到极致

负载均衡也不例外。通过测量找出系统的瓶颈，然后努力消除瓶颈以发挥性能。

## 寻找瓶颈的基本流程

* 查看平均负载（load average）
* 确认CPU，I/O有无瓶颈

## 查看平均负载

* 首先， 确认负载的第一步就是top， uptime等命令显示的平均负载（load average）。但是， 仅通过平均负载是无法判断瓶颈原因的。 应该从平均负载数值处着手， 开始调查瓶颈。
* 负载很低， 但系统的吞吐量无法提高的现象也时有发生。这种情况下应该检查软件设置是否正常， 检查网络和远程主机是否存在故障。

## 查找CPU和I/O的瓶颈

平均负载过高时， 要在CPU或者I/O中寻找原因。sar或vmstate可以查看CPU使用情况和I/O等待率随着时间的推移情况，作为参考。

“CPU负载”过高时， 用以下流程寻找原因：

* 确认是用户程序处理的瓶颈，还是系统程序的原因
* 再通过ps可查看进程的状态和CPU使用时间等， 确定导致问题的进程
* 确定进程之后， 想要进一步寻找原因的话， 可以通过strace追踪， 或oprofile进行刨测， 以确定瓶颈所在。

“I/O负载”过高， 多半是程序发出的I/O请求过多导致负载过高， 或是发生页面交换导致频繁访问磁盘。

如果是发生页面交换的情况， 应该从以下几点着手调查：

* 用Ps确认是否有进程消耗了大量的内存
* 如果由于程序故障造成内存消耗过大， 应改进程序
* 如果是因为内存不足， 就要增加内存。 无法增加内存时考虑分布式。

如果是没有交换发生， 而且磁盘I/O频繁的情况， 可能是用于缓存的内存不足。 根据服务器拥有的数据量和可增加的内存量， 按照一下步骤选择应对方法：

* 如果通过增加内存可以扩大缓存， 就增加内存
* 如果增加内存还不够用， 就考虑分散存储数据， 或增加缓存服务器等。

## 操作系统调优， 就是找出负载原因并去除之

调优的真正含义是 “找到瓶颈并去除之”

---

# 可扩展性的要点

## 扩展和可扩展性

将大量廉价的， 性能一般的硬件放在一起以提升系统性能的“横向扩展”（scale out）方案流行。因为它更适合大多数Web服务，虽然原因多种多样，但价格低廉和系统结构灵活是最重要的原因。

## 可扩展性的要点——CPU负载和I/O负载

代理服务器或应用服务器，基本上只消耗CPU。相反，数据库服务器需要较多I/O资源。

## Web应用程序和负载的关系

CPU负载服务器， 只须增加与原有服务器结构完全相同的服务器， 负载均衡器（load balancer）负责均匀的分发请求， 这样就OK了。

## 数据库的可扩展性很难保证

大规模环境中产生I/O负载的服务器本来就很难分散， 再加上频繁产生的磁盘I/O， 很容易导致服务器变慢， 这才是本质的问题。

---

# 处理大规模数据的基础知识

## 面向程序员的大规模数据的基础

1. 处理大规模数据的三个重点——写程序的技巧
* 能在内存中完成多少？ 将磁盘寻道次数降到最低。实现分布式， 有效利用局部性。
* 能应对数据量增加的算法和数据结构 例如：线性搜索->二叉树搜索
* 数据压缩， 信息搜索技术
2. 处理大规模数据之前的三大前提知识——程序开发的底层基础
* 操作系统的缓存
* 以分布式为前提的RDBMS应用
* 算法和数据结构

---

# 操作系统的缓存机制

## 在理解操作系统缓存的基础上编写应用程序——页面缓存

Linux上有页面缓存（page cache），文件缓存（file cache），缓存区缓存（buffer cache）这些机制。
