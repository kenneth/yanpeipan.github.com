---
layout: post
title: "大规模Web服务开发技术"
description: ""
category: 
tags: []
---
{% include JB/setup %}

---

# 大规模Web服务的开发定位——掌握整体


## 大规模和小规模服务

* Alexa排名
* 服务规模可以大致通过服务器数量来把握， 从这个观点来说， 上百台至几千台左右可以称为大规模。

#### 小规模服务和大规模服务的区别

1. 保证可扩展性， 负载均衡的必要性
* 横向扩展（scale out）：通过增加服务器数量来提高系统整体的处理能力并分担负载。
* 纵向扩展（scale up）：通过提高硬件性能来提高处理能力。
2. 保证冗余性
3. 低成本运维的重要性
4. 开发人数和开发方法的变化

### 应对大规模数据量

现代计算机的特点， 就是各层之间的速度差异非常大。即使操作系统和中间件再努力，也是有极限的。数据量增大， 就会经常发生缓存不命中， 结果就要多次访问低速磁盘。进入磁盘I/O（输入输出）等待队列的程序在等待读取完成之时，即使其他资源空闲， 也无法进行下一步处理。这就会导致系统整体的速度下降。

---

## 持续增长的服务和大规模化的障碍

### 系统增长战略——最小化开端， 预见变化的管理和设计

1. 事先考虑到未来系统规模会变大，从而一开始就建立完善的负载均衡系统的话，成本实在是太高了。
2. 不假思索地开始也是欠考虑的。数据规模增大引起的I/O负载上升并不是平滑增加。从缓存不命中开始只需片刻， 问题就会急剧显露出来， 引起人们注意时， 系统速度就已经开始下降了——这种事情是极其常见的。
3. 最小化开端， 在关键的地方为将来的增长做好规划， 又不致花费过多的开销。

---

# 大规模数据处理入门——内存和磁盘，Web应用程序和负载

## 大规模数据处理的难点——内存和磁盘

### 为何处理大规模数据如此困难——因为无法在内存中计算

无法在内存中计算的话， 就必须搜索磁盘上的数据， 但是磁盘十分缓慢， I/O十分耗费时间。

### 内存和磁盘的速度差异——内存要快10^5-10^6倍

内存比磁盘快10w-100w倍。

### 操作系统层的加速处理

操作系统将连续的数据放在同一处， 一次性读取4KB（kilobytes）左右。其结果就是将磁盘旋转次数降到最低。这种处理尽量减少磁盘旋转。尽管如此， 旋转一次也需要花费毫秒级，所以与内存的速度差异还是不可避免的。

### 传输速度和总线的速度差异

内存的搜索速度是磁盘的10^5-10^6倍以上， 不论内存还是磁盘， 都用总线与CPU连接。 这些总线的传输速度也有差异。连接内存和CPU的总线相当快，能达到7.5G/s， 但磁盘只能达到58M/s。SSD（solid State Drive， 固态硬盘）不需要物理旋转即可进行高速搜索， 但由于总线速度的瓶颈以及其他结构的影响， 其速度还是无法与内存相比。

在现代计算机上编写应用程序时， 必须考虑到内存和磁盘的速度差异。这是考虑可扩展性（scalability)时及其主要的一点， 也是非常困难的一点。

### 不要推测， 要测量——将一台服务器的性能发挥到极致

负载均衡也不例外。通过测量找出系统的瓶颈，然后努力消除瓶颈以发挥性能。

### 寻找瓶颈的基本流程

* 查看平均负载（load average）
* 确认CPU，I/O有无瓶颈

### 查看平均负载

* 首先， 确认负载的第一步就是top， uptime等命令显示的平均负载（load average）。但是， 仅通过平均负载是无法判断瓶颈原因的。 应该从平均负载数值处着手， 开始调查瓶颈。
* 负载很低， 但系统的吞吐量无法提高的现象也时有发生。这种情况下应该检查软件设置是否正常， 检查网络和远程主机是否存在故障。

### 查找CPU和I/O的瓶颈

平均负载过高时， 要在CPU或者I/O中寻找原因。sar或vmstate可以查看CPU使用情况和I/O等待率随着时间的推移情况，作为参考。

“CPU负载”过高时， 用以下流程寻找原因：

* 确认是用户程序处理的瓶颈，还是系统程序的原因
* 再通过ps可查看进程的状态和CPU使用时间等， 确定导致问题的进程
* 确定进程之后， 想要进一步寻找原因的话， 可以通过strace追踪， 或oprofile进行刨测， 以确定瓶颈所在。

“I/O负载”过高， 多半是程序发出的I/O请求过多导致负载过高， 或是发生页面交换导致频繁访问磁盘。

如果是发生页面交换的情况， 应该从以下几点着手调查：

* 用Ps确认是否有进程消耗了大量的内存
* 如果由于程序故障造成内存消耗过大， 应改进程序
* 如果是因为内存不足， 就要增加内存。 无法增加内存时考虑分布式。

如果是没有交换发生， 而且磁盘I/O频繁的情况， 可能是用于缓存的内存不足。 根据服务器拥有的数据量和可增加的内存量， 按照一下步骤选择应对方法：

* 如果通过增加内存可以扩大缓存， 就增加内存
* 如果增加内存还不够用， 就考虑分散存储数据， 或增加缓存服务器等。

### 操作系统调优， 就是找出负载原因并去除之

调优的真正含义是 “找到瓶颈并去除之”

---

## 可扩展性的要点

### 扩展和可扩展性

将大量廉价的， 性能一般的硬件放在一起以提升系统性能的“横向扩展”（scale out）方案流行。因为它更适合大多数Web服务，虽然原因多种多样，但价格低廉和系统结构灵活是最重要的原因。

### 可扩展性的要点——CPU负载和I/O负载

代理服务器或应用服务器，基本上只消耗CPU。相反，数据库服务器需要较多I/O资源。

### Web应用程序和负载的关系

CPU负载服务器， 只须增加与原有服务器结构完全相同的服务器， 负载均衡器（load balancer）负责均匀的分发请求， 这样就OK了。

### 数据库的可扩展性很难保证

大规模环境中产生I/O负载的服务器本来就很难分散， 再加上频繁产生的磁盘I/O， 很容易导致服务器变慢， 这才是本质的问题。

### 两种负载与Web应用程序

1. CPU负载 程序的处理速度依赖于CPU的计算速度。也称为“计算密集型程序”（CPU bound）
2. I/O负载 程序的处理速度依赖于磁盘的读取速度， 即依赖于输入/输出。这种给I/O加上负载的程序成为“I/O密集型程序”

### 多任务操作系统和负载

top的输出结果包含为“load average”（平均负载）的数字。平均负载从左到右分别为1分钟，5分钟， 15分钟内单位时间中处于等待状态的任务数。平均负载高， 说明有相应数量的任务在等待， 可以认为运行有延迟， 也就是负载过高。

### 平均负载揭示的实际负载状况

硬件每隔一定周期给CPU发送中断信号。每次发生中断时， CPU就会进行与时间相关的处理。平均负载就是在每次定时器中断（Timer Interrupt）发生时计算的。

平均负载中的负载的意思就是：

* 等待赋予CPU的执行权限的进程
* 等待磁盘I/O完成的进程

平均负载本身是将两种负载综合的结果， 单凭该数字无法判断是CPU负载高， 还是I/O负载高。

---

## 处理大规模数据的基础知识

### 面向程序员的大规模数据的基础

1. 处理大规模数据的三个重点——写程序的技巧
* 能在内存中完成多少？ 将磁盘寻道次数降到最低。实现分布式， 有效利用局部性。
* 能应对数据量增加的算法和数据结构 例如：线性搜索->二叉树搜索
* 数据压缩， 信息搜索技术
2. 处理大规模数据之前的三大前提知识——程序开发的底层基础
* 操作系统的缓存
* 以分布式为前提的RDBMS应用
* 算法和数据结构

### 平均负载之后是CPU使用率和I/O等待率

负载过大而导致性能下降的原因绝大多数都是CPU或I/O某个出了问题， 可以按照以下方法调查哪个出了问题。

1. 通过sar查看CPU使用率和I/O等待率 `%user`是CPU在用户模式下的使用率， `%system`为系统模式下的使用率
2. I/O密集型场合的sar状态 `%iowait` 是I/O等待率
3. 多CPU与CPU使用率 `sar -P ALL`

---

# 操作系统的缓存和分布式——高效处理大规模数据的原则

## 操作系统的缓存机制

### 在理解操作系统缓存的基础上编写应用程序——页面缓存

Linux上有页面缓存（page cache），文件缓存（file cache），缓存区缓存（buffer cache）这些机制。

### 虚拟内存机制

由于操作系统将物理硬件抽象化， 因此才产生了虚拟内存。

* 具有让进程更容易地访问内存等好处
* 操作系统在内核中将内存抽象化
* 操作系统以页面为单位分配物理内存并管理

### Linux页面缓存原理

内核分配过的内存不会释放， 而是一直保留下来（即页面缓存）

### VFS

磁盘缓存就是像这样由页面缓存实现的， 但实际上操作磁盘的设备驱动程序和操作系统之间还夹着一层文件系统VFS（Virtual File System， 虚拟文件系统）， 负责将不同实现方式的文件系统抽象化。

### Linux以页面为单位缓存磁盘

操作系统以块为单位读出缓存的内存， 所以只能对文件某一部分， 或读出部分缓存。

页面=虚拟内存的最小单位

LRU(Least Recently Used)， 放弃最老的内容， 留下最新的内容。

Linux使用inode编号来识别文件， 以文件的inode编号和表示内容在文件中位置的偏移量两个值作为键进行缓存。操作系统内部使用了名为Radix Tree的数据结构， 保证缓存的搜索速度不会降低。

### 内存空闲时就缓存——通过sar确认

Linux会把全部空闲内存用于缓存， 通过`sar -r`。`kbcached`为`kilo byte cached`的省略， 即用于缓存的容量。

### 增加内存降低I/O负载

### 页面缓存是透明的

## 降低I/O负载的策略

### 以缓存为前提的降低I/O负载的策略

1. 如果数据规模小于物理内存， 就全部缓存;
* 以缓存为前提的降低I/O负载的策略是有效的
* 大规模数据处理时数据压缩很重要， 比如一般的压缩算法如LZ算法等， 对于文本文件能压缩到一半左右
2. 考虑与经济成本的平衡性
* 选择性能上最为经济的服务器
* 硬件成本突然增加时，改进软件更合适

### 扩展到多台服务器——无法全部缓存的情况

* CPU负载分散只需简单的增加
* I/O分散需要考虑局部性

### 单纯增加数量无法保证可扩展性

无法缓存的比例依然不变， 立即再次成为瓶颈

### 降低I/O负载和页面缓存

Linux以4KB的小块来管理内存空间， 这种4KB的块成为“页面”。

1. 页面缓存起到的降低I/O负载的效果
2. 要先读取一次磁盘才会页面缓存

---

## 利用局部性的分布式

1. 根据访问模式实施分布式
2. 不再有无法缓存的数据

### Partitioning——考虑局部性的分布式

Partitioning  就是将一个数据库分割到多台服务器上。

1. 以RDBMS的表为单位分割
2. 从数据中间分割
3. 根据用途将系统分成不同的“岛”

### 根据访问模式分割成“岛”——考虑局部性的分布式

一般请求， 爬虫和图像分别分到不同的“岛”上。

### 以页面缓存为前提的基本应用规则

* 操作系统刚启动时不要将服务器投入到生产环境
* 性能测试要在缓存优化后进行

---

# 数据库的横向扩展策略——以分布式为基础的MySQL应用

## 正确应用索引——分布式MySQL应用的打前提

### 分布式MySQL应用的三大要点

* 灵活应用操作系统缓存
* 正确设置索引
* 以横向扩展为前提的设计

### 灵活应用操作系统缓存

1. 考虑全部数据量
* 保持数据量小于物理内存
* 内存不足时增加内存等
2. 考虑表结构设计对数据大小的影响（亿条数据， 表结构稍有错误， 数据量就会以GB为单位增减）

### 索引的重点——B树

1. index=索引
2. B+树
* 搜索外部存储设备时能将寻道次数最小化的树结构（可以将各节点的大小设定在一个合适的范围内——4KB左右
* 搜索复杂度：O(n) -> O(logn)

### 索引的效果

不仅能改善复杂度， 还能改善磁盘寻道次数。这是B树与其他复杂度同样是O（logn)的树的区别

### 确认索引是否有效的方法——explain命令

---

## MySQL的分布式——以扩展为前提的系统设计

### MySQL的replication功能

1. master/slave的架构
2. 查询发给slave， 更新发给master
* 通过ORM来控制

### master/slave的特性——对参照系进行扩展， 更新类不扩展

1. 查询可以扩展
* 只需增加服务器即可
* 但是， 在增加服务器之前要先安装适当的内存
2. master无法扩展
* 更新类的查询增加后情况更加严峻
* 但是， Web应用程序多数情况下90%都是读取查询
* master的负载通过表分割或更换实现方法来解决

---

## MySQL的横向扩展和Partitioning

### MySQL的横向扩展策略

若无法增加内存就用Partitioning

### 关于Partitioning（表分割）的补充

Partitioning就是充分利用局部性进行分散， 提高缓存利用效率。

### 以Partitioning为前提的设计

避免JOIN——利用where…in…

### Partitioning的代价

* 运维变得复杂
* 故障率上升

### 实现冗余化需要几台服务器

master1台+slave2台的话， 假设某台slave发生故障， 而准备好新的数据库服务器要复制数据， 但要复制数据， 就必须把剩下的那台slave停机（停止master无法写入， 停止slave无法读取）

要想完美的冗余化， 4台1组是必要的

### Partitiong的代价

1. 优点
* 降低负载
* 增加局部性， 提高缓存效果
2. 缺点
* 运维变得复杂后， 经济成本也会上升
3. Partitioning毕竟只是杀手锏
